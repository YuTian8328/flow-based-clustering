{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T06:51:09.482984Z",
     "start_time": "2021-09-08T06:51:09.477114Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans, spectral_clustering, SpectralClustering\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import normal\n",
    "# from graspy.simulations import sbm\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T06:49:44.218220Z",
     "start_time": "2021-09-08T06:49:44.211704Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T06:49:54.883802Z",
     "start_time": "2021-09-08T06:49:50.388379Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T05:32:13.568931Z",
     "start_time": "2021-09-07T05:32:13.558445Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_B_and_weight_vec(matrix,threshold):\n",
    "    N = matrix.shape[0]\n",
    "#     clustering = SpectralClustering(n_clusters=2, assign_labels=\"discretize\", random_state=0).fit(points)\n",
    "    A = np.copy(matrix)\n",
    "\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    weight_vec = []\n",
    "    cnt = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if j <= i:\n",
    "                continue\n",
    "            if A[i, j] < threshold: \n",
    "                A[i, j] = 0\n",
    "                A[j, i] = 0\n",
    "                continue\n",
    "            row.append(cnt)\n",
    "            col.append(i)\n",
    "            data.append(1)\n",
    "\n",
    "            row.append(cnt)\n",
    "            col.append(j)\n",
    "            data.append(-1)\n",
    "            cnt += 1\n",
    "            weight_vec.append(A[i, j])\n",
    "\n",
    "    B = csr_matrix((data, (row, col)), shape=(cnt, N))\n",
    "    weight_vec = np.array(weight_vec)\n",
    "    return A, B, weight_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T05:32:14.530118Z",
     "start_time": "2021-09-07T05:32:14.511574Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def algorithm(B, weight_vec, seeds, K=15000, alpha=0.01, lambda_nLasso=None, check_s=False):\n",
    "    E, N = B.shape\n",
    "#     weight_vec = np.ones(E)\n",
    "\n",
    "    Gamma_vec = np.array(1./(np.sum(abs(B), 0)))[0]  # \\in [0, 1]\n",
    "    Gamma = np.diag(Gamma_vec)\n",
    "\n",
    "    Sigma = 0.5\n",
    "    samplingset = seeds\n",
    "\n",
    "    seednodesindicator= np.zeros(N)\n",
    "    seednodesindicator[samplingset] = 1\n",
    "    \n",
    "    \n",
    "    noseednodeindicator = np.ones(N)\n",
    "    noseednodeindicator[samplingset] = 0\n",
    "    \n",
    "    \n",
    "    if lambda_nLasso == None:\n",
    "        lambda_nLasso = 2 / math.sqrt(np.sum(weight_vec))\n",
    "    \n",
    "    if check_s:\n",
    "        s = 0.0\n",
    "        for item in range(len(weight_vec)):\n",
    "            x = B[item].toarray()[0]\n",
    "            i = np.where(x == -1)[0][0]\n",
    "            j = np.where(x == 1)[0][0]\n",
    "            if i < N1 <= j:\n",
    "                s += weight_vec[item]\n",
    "            elif i >= N1 > j:\n",
    "                s += weight_vec[item]\n",
    "\n",
    "        if lambda_nLasso * s >= alpha * N2 / 2:\n",
    "            print ('eq(24)', lambda_nLasso * s, alpha * N2 / 2)\n",
    "    \n",
    "    fac_alpha = 1./(Gamma_vec*alpha+1)  # \\in [0, 1]\n",
    "\n",
    "    hatx = np.zeros(N)\n",
    "    newx = np.zeros(N)\n",
    "    prevx = np.zeros(N)\n",
    "    haty = np.array([x/(E-1) for x in range(0, E)])\n",
    "    history = []\n",
    "    for iterk in range(K):\n",
    "        # if 0 < np.max(abs(newx - prevx)) < 1e-4:\n",
    "        #     print(iterk)\n",
    "        #     break\n",
    "        tildex = 2 * hatx - prevx\n",
    "        newy = haty + Sigma * B.dot(tildex)  # chould be negative\n",
    "        haty = newy / np.maximum(abs(newy) / (lambda_nLasso * weight_vec), np.ones(E))  # could be negative\n",
    "\n",
    "        newx = hatx - Gamma_vec * B.T.dot(haty)  # could  be negative\n",
    "        newx[samplingset] = (newx[samplingset] + Gamma_vec[samplingset]) / (1 + Gamma_vec[samplingset])\n",
    "\n",
    "        newx = seednodesindicator * newx + noseednodeindicator * (newx * fac_alpha)\n",
    "        prevx = np.copy(hatx)\n",
    "        hatx = newx  # could be negative\n",
    "        history.append(newx)\n",
    "    \n",
    "    history = np.array(history)\n",
    "\n",
    "    return history\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image custering on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T05:57:29.425803Z",
     "start_time": "2021-09-07T05:57:29.415442Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_digits_2clusters():\n",
    "    '''\n",
    "    Randomly select 200 images of digit \"1\" and \"3\"\n",
    "    '''\n",
    "    mnist_3 = mnist[mnist['label']==3].iloc[:1000,:]\n",
    "\n",
    "    mnist_1 = mnist[mnist['label']==1].iloc[:1000,:]\n",
    "\n",
    "    digits=mnist_3.append(mnist_1)\n",
    "    digits = digits.sample(frac=0.1).reset_index(drop=True)\n",
    "    return digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:05:21.089495Z",
     "start_time": "2021-09-06T16:05:21.080078Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_digit(affinity_matrix, threshold,seeds, K=1000, alpha=0.01, lambda_nLasso=0.1):\n",
    "\n",
    "    A,B, weight_vec = get_B_and_weight_vec(affinity_matrix,threshold)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    history = algorithm(B, weight_vec,seeds, K=K, alpha=alpha, lambda_nLasso=lambda_nLasso)\n",
    "    print('our method time: ', datetime.datetime.now() - start)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    spectral_labels = spectral_clustering(affinity_matrix,n_clusters=2)\n",
    "    print ('spectral clustering time: ', datetime.datetime.now() - start)\n",
    "    return history,spectral_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T05:58:48.491020Z",
     "start_time": "2021-09-07T05:58:48.481741Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weig_mat_2clusters(digits):\n",
    "    '''\n",
    "    Generate adjacency matrix  based on distance measure in high dimentional space\n",
    "    '''\n",
    "    weig_mat_2clusters = np.zeros((200,200))   \n",
    "    for i in range(200):\n",
    "        for j in range(200):\n",
    "            if i == j:\n",
    "                continue\n",
    "            weig_mat_2clusters[i][j]=np.exp(-norm(digits.iloc[i,1:]-digits.iloc[j,1:])/1000)\n",
    "    return weig_mat_2clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T05:39:03.320227Z",
     "start_time": "2021-09-07T05:39:03.302929Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_digit(matrix, threshold,K=1000, seeds=seeds, alpha=0.2, lambda_nLasso=0.1):\n",
    "    A,B, weight_vec = get_B_and_weight_vec(matrix,threshold)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    history = algorithm(B, weight_vec,seeds = seeds, K=K, alpha=alpha, lambda_nLasso=lambda_nLasso)\n",
    "    print('our method time: ', datetime.datetime.now() - start)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    spectral_labels = spectral_clustering(matrix,n_clusters=2)\n",
    "#     spectral_labels = SpectralClustering(2).fit(digits.iloc[:,1:]).labels_\n",
    "    print ('spectral clustering time: ', datetime.datetime.now() - start)\n",
    "    \n",
    "    return history,spectral_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T06:25:11.782471Z",
     "start_time": "2021-09-07T06:14:02.893711Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our method time:  0:00:00.039293\n",
      "spectral clustering time:  0:00:00.023383\n",
      "our method time:  0:00:00.042036\n",
      "spectral clustering time:  0:00:00.019869\n",
      "our method time:  0:00:00.054367\n",
      "spectral clustering time:  0:00:00.032394\n",
      "our method time:  0:00:00.046315\n",
      "spectral clustering time:  0:00:00.033510\n",
      "our method time:  0:00:00.039756\n",
      "spectral clustering time:  0:00:00.019892\n",
      "our method time:  0:00:00.040082\n",
      "spectral clustering time:  0:00:00.021559\n",
      "our method time:  0:00:00.048948\n",
      "spectral clustering time:  0:00:00.025837\n",
      "our method time:  0:00:00.043275\n",
      "spectral clustering time:  0:00:00.024941\n",
      "our method time:  0:00:00.044286\n",
      "spectral clustering time:  0:00:00.022470\n",
      "our method time:  0:00:00.041615\n",
      "spectral clustering time:  0:00:00.021209\n",
      "our method time:  0:00:00.044696\n",
      "spectral clustering time:  0:00:00.030415\n",
      "our method time:  0:00:00.039906\n",
      "spectral clustering time:  0:00:00.020732\n",
      "our method time:  0:00:00.038186\n",
      "spectral clustering time:  0:00:00.020011\n",
      "our method time:  0:00:00.061761\n",
      "spectral clustering time:  0:00:00.046888\n",
      "our method time:  0:00:00.040538\n",
      "spectral clustering time:  0:00:00.020038\n",
      "our method time:  0:00:00.041392\n",
      "spectral clustering time:  0:00:00.021441\n",
      "our method time:  0:00:00.047422\n",
      "spectral clustering time:  0:00:00.030203\n",
      "our method time:  0:00:00.039227\n",
      "spectral clustering time:  0:00:00.022227\n",
      "our method time:  0:00:00.043650\n",
      "spectral clustering time:  0:00:00.024379\n",
      "our method time:  0:00:00.042894\n",
      "spectral clustering time:  0:00:00.025722\n"
     ]
    }
   ],
   "source": [
    "# Repeatedly run the experiment\n",
    "our_accus_2clusters = []\n",
    "spec_accus_2clusters = []\n",
    "for i in range(20):\n",
    "    digits = get_digits_2clusters()\n",
    "    true_labels = np.array([0 if i==3 else 1 for i in digits.label])\n",
    "    weig_mat_2clusters = get_weig_mat_2clusters(digits)\n",
    "    num_seeds = 0.2*100\n",
    "    seeds = np.random.choice(np.argwhere(digits.label.values==1).squeeze(),int(num_seeds))\n",
    "    history,spectral_labels = run_digit(weig_mat_2clusters,threshold=0.25,K=300, seeds=seeds, \\\n",
    "                                        alpha=0.01, lambda_nLasso=0.1)\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(np.nan_to_num(history[-1].reshape(-1,1)))\n",
    "    if sum(kmeans.labels_ == true_labels) >= 100:\n",
    "        our_accu = sum(kmeans.labels_ == true_labels)/len(true_labels)\n",
    "    else:\n",
    "        our_accu =(len(true_labels)-sum(kmeans.labels_ == true_labels))/len(true_labels)\n",
    "    \n",
    "    our_accus_2clusters.append(our_accu)\n",
    "    if sum(spectral_labels == true_labels) >= 100:\n",
    "        spec_accu = sum(spectral_labels== true_labels)/len(true_labels)\n",
    "    else:\n",
    "        spec_accu = (len(true_labels)-sum(spectral_labels == true_labels))/len(true_labels)\n",
    "    spec_accus_2clusters.append(spec_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T06:31:13.442617Z",
     "start_time": "2021-09-07T06:31:13.434253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9842500000000001,\n",
       " 0.9279999999999999,\n",
       " 0.008104782538723671,\n",
       " 0.06038211655780212)"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(our_accus_2clusters), np.mean(spec_accus_2clusters),np.std(our_accus_2clusters),np.std(spec_accus_2clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T17:24:22.406967Z",
     "start_time": "2021-09-06T17:24:22.373082Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.cluster import spectral_clustering, SpectralClustering\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster, datasets, mixture\n",
    "\n",
    "n_samples = 6000\n",
    "\n",
    "def accuracy(labels, true_labels):\n",
    "    total_common = 0\n",
    "    cluster_names = set(true_labels)\n",
    "    permutations = list(itertools.permutations(cluster_names))\n",
    "    for permutation in permutations:\n",
    "        max_common = 0\n",
    "        for i, cluster_name in enumerate(cluster_names):\n",
    "            cluster_nodes = np.where(labels == cluster_name)[0]\n",
    "            cluster_name1 = permutation[i]\n",
    "            true_nodes = np.where(true_labels == cluster_name1)[0]\n",
    "\n",
    "            common = len(set(true_nodes) - (set(true_nodes) - set(cluster_nodes)))\n",
    "            max_common += common\n",
    "\n",
    "        total_common = max(total_common, max_common)\n",
    "\n",
    "    return total_common / len(true_labels)\n",
    "\n",
    "def get_B_and_weight_vec_digits(matrix):\n",
    "    A = np.copy(matrix)\n",
    "    N = matrix.shape[0]\n",
    "\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    weight_vec = []\n",
    "    cnt = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if j <= i:\n",
    "                continue\n",
    "            if A[i, j] < 0.15:\n",
    "                A[i, j] = 0\n",
    "                A[j, i] = 0\n",
    "                continue\n",
    "            row.append(cnt)\n",
    "            col.append(i)\n",
    "            data.append(1)\n",
    "\n",
    "            row.append(cnt)\n",
    "            col.append(j)\n",
    "            data.append(-1)\n",
    "            cnt += 1\n",
    "            weight_vec.append(A[i, j])\n",
    "\n",
    "    B = csr_matrix((data, (row, col)), shape=(cnt, N))\n",
    "    weight_vec = np.array(weight_vec)\n",
    "    return B, weight_vec\n",
    "\n",
    "\n",
    "def run_multi_digits(matrix, true_labels, K, alpha, lambda_nLasso,n_clusters, M=0.2):\n",
    "    B, weight_vec = get_B_and_weight_vec_digits(matrix)\n",
    "    E,N=B.shape[0],B.shape[1]\n",
    "\n",
    "    Gamma_vec = np.array(1. / (np.sum(abs(B), 0)))[0]  # \\in [0, 1]\n",
    "    Gamma = np.diag(Gamma_vec)\n",
    "\n",
    "    Sigma = 0.5\n",
    "\n",
    "    fac_alpha = 1. / (Gamma_vec * alpha + 1)  # \\in [0, 1]\n",
    "    lambda_weight = lambda_nLasso * weight_vec\n",
    "\n",
    "    our_labels = np.full(N, n_clusters-1)\n",
    "    our_time = datetime.datetime.now() - datetime.datetime.now()\n",
    "    for clust_num in range(n_clusters-1):\n",
    "\n",
    "        samplingset = random.choices(np.where(true_labels==clust_num)[0], k=int(M * len(np.where(true_labels==clust_num)[0])))\n",
    "        seednodesindicator = np.zeros(N)\n",
    "        seednodesindicator[samplingset] = 1\n",
    "        noseednodeindicator = np.ones(N)\n",
    "        noseednodeindicator[samplingset] = 0\n",
    "\n",
    "\n",
    "        hatx = np.zeros(N)\n",
    "        newx = np.zeros(N)\n",
    "        prevx = np.zeros(N)\n",
    "        haty = np.array([x / (E - 1) for x in range(0, E)])\n",
    "        gamma_plus = 1 + Gamma_vec[samplingset]\n",
    "        start = datetime.datetime.now()\n",
    "        for iterk in range(K):\n",
    "            tildex = 2 * hatx - prevx\n",
    "            newy = haty + Sigma * B.dot(tildex)  # chould be negative\n",
    "            res = abs(newy) / lambda_weight\n",
    "            res[res < 1] = 1\n",
    "            haty = newy / res\n",
    "\n",
    "            newx = hatx - Gamma_vec * B.T.dot(haty)  # could  be negative\n",
    "\n",
    "            newx[samplingset] = (newx[samplingset] + Gamma_vec[samplingset]) / gamma_plus\n",
    "\n",
    "            newx = seednodesindicator * newx + noseednodeindicator * (newx * fac_alpha)\n",
    "            prevx = np.copy(hatx)\n",
    "            hatx = newx  # could be negative\n",
    "        our_time += datetime.datetime.now() - start\n",
    "        X = newx\n",
    "        X = np.nan_to_num(X, 0)\n",
    "        kmeans = KMeans(n_clusters=2, random_state=0).fit(X.reshape(len(X), 1))\n",
    "        matched_label = kmeans.labels_[samplingset][0]\n",
    "        our_labels[np.where(kmeans.labels_ == matched_label)[0]] = clust_num\n",
    "    \n",
    "    print ('our time is:', our_time)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    labels = spectral_clustering(matrix, n_clusters=3,random_state=1)\n",
    "#     labels = SpectralClustering(3).fit(X056).labels_\n",
    "    print ('spectral clustering time is:', datetime.datetime.now() - start)\n",
    "    our_accuracy = accuracy(our_labels, true_labels)\n",
    "    spec_accuracy = accuracy(labels, true_labels)\n",
    "    \n",
    "    return our_accuracy, spec_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T17:43:11.334299Z",
     "start_time": "2021-09-06T17:43:11.104905Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_digits_3clusters():\n",
    "    '''\n",
    "    Randomly select 300 images of digit \"0\",\"5\" and \"6\"\n",
    "    '''\n",
    "    mnist_5 = mnist[mnist['label']==5].iloc[:1000,:].sample(frac=0.1).reset_index(drop=True)\n",
    "    mnist_0 = mnist[mnist['label']==0].iloc[:1000,:].sample(frac=0.1).reset_index(drop=True)\n",
    "    mnist_6 = mnist[mnist['label']==6].iloc[:1000,:].sample(frac=0.1).reset_index(drop=True)\n",
    "    digits_3clusters = mnist_0.append(mnist_5,ignore_index=True).append(mnist_6,ignore_index=True)\n",
    "    return digits_3clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T17:45:06.031976Z",
     "start_time": "2021-09-06T17:43:39.739908Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_weig_mat_3clusters(digits):\n",
    "    '''\n",
    "    Generate adjacency matrix based on distance measure in high dimentional space\n",
    "    '''\n",
    "    weig_mat_3clusters = np.zeros((300,300))    #adjacency matrix based on neighbor probabilty.\n",
    "    for i in range(300):\n",
    "        for j in range(300):\n",
    "            if i == j:\n",
    "                continue\n",
    "            weig_mat_3clusters[i][j]=np.exp(-norm(digits.iloc[i,1:]-digits.iloc[j,1:])/1000)\n",
    "    return weig_mat_3clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T19:00:52.833169Z",
     "start_time": "2021-09-06T18:47:55.871229Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our time is: 0:00:00.095289\n",
      "spectral clustering time is: 0:00:00.051400\n",
      "our time is: 0:00:00.094048\n",
      "spectral clustering time is: 0:00:00.043544\n",
      "our time is: 0:00:00.091935\n",
      "spectral clustering time is: 0:00:00.040619\n",
      "our time is: 0:00:00.093330\n",
      "spectral clustering time is: 0:00:00.039564\n",
      "our time is: 0:00:00.094307\n",
      "spectral clustering time is: 0:00:00.042665\n",
      "our time is: 0:00:00.094526\n",
      "spectral clustering time is: 0:00:00.034100\n",
      "our time is: 0:00:00.095031\n",
      "spectral clustering time is: 0:00:00.039788\n",
      "our time is: 0:00:00.091518\n",
      "spectral clustering time is: 0:00:00.045876\n",
      "our time is: 0:00:00.102445\n",
      "spectral clustering time is: 0:00:00.046759\n",
      "our time is: 0:00:00.094498\n",
      "spectral clustering time is: 0:00:00.042947\n"
     ]
    }
   ],
   "source": [
    "# Repeatedly run the experiment\n",
    "true_labels = np.array([0 for i in range(100)] + [1 for i in range(100)] + [2 for i in range(100)])\n",
    "our_accus = []\n",
    "spec_accus = []\n",
    "for i in range(10):\n",
    "    digits_3clusters = get_digits_3clusters()\n",
    "    weig_mat_3clusters = get_weig_mat_3clusters(digits_3clusters)\n",
    "    \n",
    "    our_accu, spec_accu = run_multi_digits(matrix=weig_mat_3clusters,true_labels=true_labels, K=300,\\\n",
    "                 alpha=0.01, lambda_nLasso=0.2,n_clusters=3)\n",
    "    our_accus.append(our_accu)\n",
    "    spec_accus.append(spec_accu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T19:07:06.340044Z",
     "start_time": "2021-09-06T19:07:06.323214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8866666666666667,\n",
       " 0.8566666666666667,\n",
       " 0.91,\n",
       " 0.5833333333333334,\n",
       " 0.9466666666666667,\n",
       " 0.8433333333333334,\n",
       " 0.9466666666666667,\n",
       " 0.92,\n",
       " 0.8933333333333333,\n",
       " 0.89]"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_accus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T19:07:09.051235Z",
     "start_time": "2021-09-06T19:07:09.036082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8676666666666668, 0.752, 0.10004498987955368, 0.07578038444522876)"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(our_accus),np.mean(spec_accus),np.std(our_accus),np.std(spec_accus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "301.1666564941406px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
